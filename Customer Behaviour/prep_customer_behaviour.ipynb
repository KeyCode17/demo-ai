{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36339e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c643cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Dataset shape: (7043, 21)\n",
      "\n",
      "First few rows:\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Applying binary encoding to: ['Churn', 'PhoneService', 'PaperlessBilling', 'Partner', 'Dependents']\n",
      "‚úÖ Churn: ['No' 'Yes'] -> [0 1]\n",
      "‚úÖ PhoneService: ['No' 'Yes'] -> [0 1]\n",
      "‚úÖ PaperlessBilling: ['Yes' 'No'] -> [1 0]\n",
      "‚úÖ Partner: ['Yes' 'No'] -> [1 0]\n",
      "‚úÖ Dependents: ['No' 'Yes'] -> [0 1]\n",
      "\n",
      "Applying label encoding to: ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod', 'gender', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
      "\n",
      "‚úÖ MultipleLines mapping:\n",
      "   No phone service -> 1\n",
      "   No -> 0\n",
      "   Yes -> 2\n",
      "\n",
      "‚úÖ InternetService mapping:\n",
      "   DSL -> 0\n",
      "   Fiber optic -> 1\n",
      "   No -> 2\n",
      "\n",
      "‚úÖ Contract mapping:\n",
      "   Month-to-month -> 0\n",
      "   One year -> 1\n",
      "   Two year -> 2\n",
      "\n",
      "‚úÖ PaymentMethod mapping:\n",
      "   Electronic check -> 2\n",
      "   Mailed check -> 3\n",
      "   Bank transfer (automatic) -> 0\n",
      "   Credit card (automatic) -> 1\n",
      "\n",
      "‚úÖ gender mapping:\n",
      "   Female -> 0\n",
      "   Male -> 1\n",
      "\n",
      "‚úÖ OnlineSecurity mapping:\n",
      "   No -> 0\n",
      "   Yes -> 2\n",
      "   No internet service -> 1\n",
      "\n",
      "‚úÖ OnlineBackup mapping:\n",
      "   Yes -> 2\n",
      "   No -> 0\n",
      "   No internet service -> 1\n",
      "\n",
      "‚úÖ DeviceProtection mapping:\n",
      "   No -> 0\n",
      "   Yes -> 2\n",
      "   No internet service -> 1\n",
      "\n",
      "‚úÖ TechSupport mapping:\n",
      "   No -> 0\n",
      "   Yes -> 2\n",
      "   No internet service -> 1\n",
      "\n",
      "‚úÖ StreamingTV mapping:\n",
      "   No -> 0\n",
      "   Yes -> 2\n",
      "   No internet service -> 1\n",
      "\n",
      "‚úÖ StreamingMovies mapping:\n",
      "   No -> 0\n",
      "   Yes -> 2\n",
      "   No internet service -> 1\n",
      "\n",
      "Total label encoders created: 11\n",
      "\n",
      "Processing numeric columns...\n",
      "Missing values before filling:\n",
      "  TotalCharges: 11 missing values\n",
      "  MonthlyCharges: 0 missing values\n",
      "  tenure: 0 missing values\n",
      "Missing values after filling:\n",
      "  TotalCharges: 0 missing values\n",
      "  MonthlyCharges: 0 missing values\n",
      "  tenure: 0 missing values\n",
      "\n",
      "Original columns: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
      "‚úÖ Removed customerID\n",
      "\n",
      "Features shape: (7043, 19)\n",
      "Target shape: (7043,)\n",
      "Feature columns: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges']\n",
      "\n",
      "Data quality check:\n",
      "Features - NaN values: 0\n",
      "Features - Infinite values: False\n",
      "Target distribution:\n",
      "Churn\n",
      "0    5174\n",
      "1    1869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applying StandardScaler...\n",
      "Scaling completed:\n",
      "  Original shape: (7043, 19)\n",
      "  Scaled shape: (7043, 19)\n",
      "  Scaled mean (should be ~0): [-2.21950024e-17 -4.84254598e-17  7.16293259e-17  1.06939557e-16\n",
      " -2.42127299e-17]...\n",
      "  Scaled std (should be ~1): [1. 1. 1. 1. 1.]...\n",
      "\n",
      "Data split:\n",
      "  Training set: (4930, 19)\n",
      "  Validation set: (1056, 19)\n",
      "  Test set: (1057, 19)\n",
      "\n",
      "==================================================\n",
      "SAVING PREPROCESSORS\n",
      "==================================================\n",
      "‚úÖ Scaler saved as 'scaler.pkl'\n",
      "‚úÖ Label encoders saved as 'label_encoders.pkl'\n",
      "‚úÖ Preprocessing info saved as 'preprocessing_info.pkl'\n",
      "\n",
      "Verifying saved files...\n",
      "‚úÖ All files loaded successfully!\n",
      "‚úÖ Scaler type: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "‚úÖ Number of label encoders: 11\n",
      "‚úÖ Input features: 19\n",
      "‚úÖ Feature columns: 19\n",
      "\n",
      "==================================================\n",
      "PREPROCESSING SUMMARY\n",
      "==================================================\n",
      "üìä Dataset: 7043 rows, 21 original columns\n",
      "üî¢ Final features: 19 columns\n",
      "üìÅ Files saved:\n",
      "   ‚Ä¢ scaler.pkl (StandardScaler)\n",
      "   ‚Ä¢ label_encoders.pkl (11 LabelEncoders)\n",
      "   ‚Ä¢ preprocessing_info.pkl (metadata)\n",
      "üéØ Target: {0: 5174, 1: 1869}\n",
      "‚ú® Data ready for model training!\n",
      "\n",
      "========================================\n",
      "NEW DATA PREPROCESSING PREVIEW\n",
      "========================================\n",
      "Your new data should have these columns:\n",
      " 1. gender\n",
      " 2. SeniorCitizen\n",
      " 3. Partner\n",
      " 4. Dependents\n",
      " 5. tenure\n",
      " 6. PhoneService\n",
      " 7. MultipleLines\n",
      " 8. InternetService\n",
      " 9. OnlineSecurity\n",
      "10. OnlineBackup\n",
      "11. DeviceProtection\n",
      "12. TechSupport\n",
      "13. StreamingTV\n",
      "14. StreamingMovies\n",
      "15. Contract\n",
      "16. PaperlessBilling\n",
      "17. PaymentMethod\n",
      "18. MonthlyCharges\n",
      "19. TotalCharges\n",
      "\n",
      "Expected input shape for model: (batch_size, 19)\n",
      "Data should be scaled using the saved scaler.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the data\n",
    "df = pd.read_csv('./Customer - Telco Data.csv')\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Define column categories\n",
    "binary_columns = ['Churn', 'PhoneService', 'PaperlessBilling', 'Partner', 'Dependents']\n",
    "other_categorical = ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod', 'gender', \n",
    "                    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                    'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "# Step 3: Create a copy for processing\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Step 4: Binary encoding (Yes/No columns)\n",
    "binary_map = {'No': 0, 'Yes': 1}\n",
    "print(f\"\\nApplying binary encoding to: {binary_columns}\")\n",
    "for col in binary_columns:\n",
    "    if col in df_encoded.columns:\n",
    "        df_encoded[col] = df_encoded[col].map(binary_map)\n",
    "        print(f\"‚úÖ {col}: {df[col].unique()} -> {df_encoded[col].unique()}\")\n",
    "\n",
    "# Step 5: Label encoding for other categorical columns\n",
    "label_encoders = {}\n",
    "print(f\"\\nApplying label encoding to: {other_categorical}\")\n",
    "\n",
    "for col in other_categorical:\n",
    "    if col in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        label_encoders[col] = le  # Store the encoder\n",
    "        \n",
    "        # Show the mapping\n",
    "        unique_original = df[col].unique()\n",
    "        unique_encoded = le.transform(unique_original)\n",
    "        mapping = dict(zip(unique_original, unique_encoded))\n",
    "        print(f\"\\n‚úÖ {col} mapping:\")\n",
    "        for original, encoded in mapping.items():\n",
    "            print(f\"   {original} -> {encoded}\")\n",
    "\n",
    "print(f\"\\nTotal label encoders created: {len(label_encoders)}\")\n",
    "\n",
    "# Step 6: Handle numeric columns and missing values\n",
    "print(\"\\nProcessing numeric columns...\")\n",
    "df_encoded['TotalCharges'] = pd.to_numeric(df_encoded['TotalCharges'], errors='coerce')\n",
    "df_encoded['MonthlyCharges'] = pd.to_numeric(df_encoded['MonthlyCharges'], errors='coerce')\n",
    "df_encoded['tenure'] = pd.to_numeric(df_encoded['tenure'], errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "numeric_columns = ['TotalCharges', 'MonthlyCharges', 'tenure']\n",
    "print(\"Missing values before filling:\")\n",
    "for col in numeric_columns:\n",
    "    missing = df_encoded[col].isna().sum()\n",
    "    print(f\"  {col}: {missing} missing values\")\n",
    "\n",
    "# Fill missing values with mean\n",
    "df_encoded[numeric_columns] = df_encoded[numeric_columns].fillna(df_encoded[numeric_columns].mean())\n",
    "\n",
    "print(\"Missing values after filling:\")\n",
    "for col in numeric_columns:\n",
    "    missing = df_encoded[col].isna().sum()\n",
    "    print(f\"  {col}: {missing} missing values\")\n",
    "\n",
    "# Step 7: Remove unnecessary columns\n",
    "print(f\"\\nOriginal columns: {list(df_encoded.columns)}\")\n",
    "if 'customerID' in df_encoded.columns:\n",
    "    df_encoded = df_encoded.drop('customerID', axis=1)\n",
    "    print(\"‚úÖ Removed customerID\")\n",
    "\n",
    "# Step 8: Separate features and target\n",
    "X = df_encoded.drop('Churn', axis=1)\n",
    "y = df_encoded['Churn']\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# Step 9: Check for any remaining issues\n",
    "print(f\"\\nData quality check:\")\n",
    "print(f\"Features - NaN values: {X.isna().sum().sum()}\")\n",
    "print(f\"Features - Infinite values: {np.any(np.isinf(X.select_dtypes(include=[np.number])))}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "\n",
    "# Step 10: Scale the features\n",
    "print(\"\\nApplying StandardScaler...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Scaling completed:\")\n",
    "print(f\"  Original shape: {X.shape}\")\n",
    "print(f\"  Scaled shape: {X_scaled.shape}\")\n",
    "print(f\"  Scaled mean (should be ~0): {np.mean(X_scaled, axis=0)[:5]}...\")\n",
    "print(f\"  Scaled std (should be ~1): {np.std(X_scaled, axis=0)[:5]}...\")\n",
    "\n",
    "# Step 11: Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training set: {X_train.shape}\")\n",
    "print(f\"  Validation set: {X_val.shape}\")\n",
    "print(f\"  Test set: {X_test.shape}\")\n",
    "\n",
    "# Step 12: Save all preprocessors\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAVING PREPROCESSORS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"‚úÖ Scaler saved as 'scaler.pkl'\")\n",
    "\n",
    "# Save the label encoders\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "print(\"‚úÖ Label encoders saved as 'label_encoders.pkl'\")\n",
    "\n",
    "# Save comprehensive preprocessing information\n",
    "preprocessing_info = {\n",
    "    'binary_columns': binary_columns,\n",
    "    'other_categorical': other_categorical,\n",
    "    'binary_map': binary_map,\n",
    "    'feature_columns': list(X.columns),\n",
    "    'input_shape': X_scaled.shape[1],\n",
    "    'target_column': 'Churn',\n",
    "    'numeric_columns': numeric_columns,\n",
    "    'expected_feature_order': list(X.columns)\n",
    "}\n",
    "\n",
    "joblib.dump(preprocessing_info, 'preprocessing_info.pkl')\n",
    "print(\"‚úÖ Preprocessing info saved as 'preprocessing_info.pkl'\")\n",
    "\n",
    "# Step 13: Verify saved files\n",
    "print(\"\\nVerifying saved files...\")\n",
    "try:\n",
    "    loaded_scaler = joblib.load('scaler.pkl')\n",
    "    loaded_encoders = joblib.load('label_encoders.pkl')\n",
    "    loaded_info = joblib.load('preprocessing_info.pkl')\n",
    "    \n",
    "    print(\"‚úÖ All files loaded successfully!\")\n",
    "    print(f\"‚úÖ Scaler type: {type(loaded_scaler)}\")\n",
    "    print(f\"‚úÖ Number of label encoders: {len(loaded_encoders)}\")\n",
    "    print(f\"‚úÖ Input features: {loaded_info['input_shape']}\")\n",
    "    print(f\"‚úÖ Feature columns: {len(loaded_info['feature_columns'])}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading files: {e}\")\n",
    "\n",
    "# Step 14: Display final summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üìä Dataset: {df.shape[0]} rows, {df.shape[1]} original columns\")\n",
    "print(f\"üî¢ Final features: {X_scaled.shape[1]} columns\")\n",
    "print(f\"üìÅ Files saved:\")\n",
    "print(f\"   ‚Ä¢ scaler.pkl (StandardScaler)\")\n",
    "print(f\"   ‚Ä¢ label_encoders.pkl ({len(label_encoders)} LabelEncoders)\")\n",
    "print(f\"   ‚Ä¢ preprocessing_info.pkl (metadata)\")\n",
    "print(f\"üéØ Target: {y.value_counts().to_dict()}\")\n",
    "print(f\"‚ú® Data ready for model training!\")\n",
    "\n",
    "# Step 15: Create a preview function for new data preprocessing\n",
    "def preprocess_new_data_preview(sample_data):\n",
    "    \"\"\"\n",
    "    Show how new data would be preprocessed\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"NEW DATA PREPROCESSING PREVIEW\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"Your new data should have these columns:\")\n",
    "    for i, col in enumerate(X.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nExpected input shape for model: (batch_size, {X_scaled.shape[1]})\")\n",
    "    print(\"Data should be scaled using the saved scaler.\")\n",
    "\n",
    "# Run the preview\n",
    "preprocess_new_data_preview(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
